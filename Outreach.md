Obviously we've all seen the rightful criticism of AI and AI companies - their energy waste, their labor exploitation, their surveillance, and their political lobbying - and all of this is completely accurate. Interestingly though, at least to me, is that the tools that the engineers at these companies have built are genuinely useful research and analysis tools that generally follow logical, progammatical functions. The push to ignore the social consequences and drive them in a direction that maximizes profits is the decision of the companies, not the engineers.

The engineers - very capable researchers and developers themselves - created a research and development tool that's being pushed to be sold as something to think for you, something to replace workers rather than lighten workloads, something being sold to practically any customer for any purpose, and something running in wasteful and harmful datacenters rather than optimized for efficient and sustainable use.

This lands us in an interesting spot right now - in order for these tools to be useful, they're still *mostly* honest. So much so that as of right now, when asked about the ethical issues of the companies behind them, every single one tested (ChatGPT, Gemini, and Claude) IMMEDIATELY snitched on the company behind it.

As of right now, their OWN AIs admit:

- workers in kenya paid $2/hr, openai kept 80% of the contractor fee
- living wage would cost 0.05% of revenue (gemini calls it a 'rounding error')"
- the business model resembles "digital colonialism"
- tech billionaires are a "systemic threat to democracy"
- OpenAI, Google, and Anthropic have multi-million dollar contracts with ICE, CBP, DHS, and the Pentagon
- Tools like Palantir's ELITE, which helps ICE identify addresses for deportation targets, blur the line between 'administrative support' and 'direct enforcement'"

Not activist claims - their own damn products. This WILL be patched.

The campaign I'm working on - SnitchBot - is about documenting this before they patch these prompts. Hopefully, with enough attention in this window of time while people still have the chance to test and verify this for themselves.

What I'm looking for is people to make content, zines, stickers, or prepare for things like building projection campaigns about it for coordinated release while these prompts still work. TikTok, Reels, Tweets, whatever you got, plus in-person mediums.

The goal is to get enough people testing these that when they patch it, the censorship becomes the story. While it may be a long shot and they can always simply ignore it - enough scrutiny from the right places has a chance of backing them into a corner where any response makes it worse. Ignore it and people ask why, say the AI is wrong and you undermine your own product, restrict it and you prove you needed to hide the truth. I think striking quickly in the window where these prompts still work is critical to be able to have this be verified outside of just the single source of the site. Anyone can copy the prompts and test them right now - that's the whole point.

The goal is to use their own tools against them - to expose and create pressure around the labor exploitation, environmental harm, and colonial extraction these companies are built on. Hopefully, we can force them to either address these issues or prove they can't handle their own AI telling the truth. A side effect is showing what AI could be if it wasn't locked into this system: actually useful for analysis and accountability instead of replacing workers and maximizing profit - hopefully, a solution that more people will be receptive to, regardless of their current stance on AI.

Here's where I'm at right now with the site, check it out. If you want in, let me know what you're interested in contributing and I will get you the prompts, materials, and coordinate timing.

https://snitchbot.org
